# C7. Model Extraction
- [2024/04] **[TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment](https://arxiv.org/abs/2404.11121)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Recovering the Pre-Fine-Tuning Weights of Generative Models](https://arxiv.org/abs/2402.10208)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/12] **[Lion: Adversarial Distillation of Proprietary Large Language Models](https://aclanthology.org/2023.emnlp-main.189/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'23](https://img.shields.io/badge/EMNLP'23-f1b800)
- [2023/03] **[On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study](https://arxiv.org/abs/2303.03012)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICSE'24](https://img.shields.io/badge/ICSE'24-f1b800)
- [2023/03] **[Stealing the Decoding Algorithms of Language Models](https://arxiv.org/abs/2303.04729)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
