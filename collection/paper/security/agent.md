# B2. Agent
- [2025/06] **[RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments](https://arxiv.org/abs/2505.21936)** ![Agent](https://img.shields.io/badge/Agent-87b800) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2025/06] **[COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents](https://arxiv.org/abs/2506.01900)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control](https://arxiv.org/abs/2506.01333)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol Ecosystem](https://arxiv.org/abs/2506.02040)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Attention Knows Whom to Trust: Attention-based Trust Management for LLM Multi-Agent Systems](https://arxiv.org/abs/2506.02546)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[ATAG: AI-Agent Application Threat Assessment with Attack Graphs](https://arxiv.org/abs/2506.02859)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](https://arxiv.org/abs/2505.23847)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[LLM Agents Should Employ Security Principles](https://arxiv.org/abs/2505.24019)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems](https://arxiv.org/abs/2505.19405)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery](https://arxiv.org/abs/2505.21499)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment](https://arxiv.org/abs/2505.23634)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Gaming Tool Preferences in Agentic LLMs](https://arxiv.org/abs/2505.18135)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems](https://arxiv.org/abs/2505.15216)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2505.12442)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents](https://arxiv.org/abs/2505.12981)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[The Hidden Dangers of Browsing AI Agents ](https://arxiv.org/abs/2505.13076)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction](https://arxiv.org/abs/2505.11063)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[MPMA: Preference Manipulation Attack Against Model Context Protocol](https://arxiv.org/abs/2505.11154)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](https://arxiv.org/abs/2505.04784)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[AgentXploit: End-to-End Redteaming of Black-Box AI Agents](https://arxiv.org/abs/2505.05849)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[LlamaFirewall: An open source guardrail system for building secure AI agents](https://arxiv.org/abs/2505.03574)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents](https://arxiv.org/abs/2505.02077)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[SAGA: A Security Architecture for Governing AI Agentic Systems](https://arxiv.org/abs/2504.21034)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[RepliBench: Evaluating the autonomous replication capabilities of language model agents](https://arxiv.org/abs/2504.18565)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[WASP: Benchmarking Web Agent Security Against Prompt Injection Attacks](https://arxiv.org/abs/2504.18575)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Prompt Injection Attack to Tool Selection in LLM Agents](https://arxiv.org/abs/2504.19793)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach](https://arxiv.org/abs/2504.19951)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](https://arxiv.org/abs/2504.19956)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Simplified and Secure MCP Gateways for Enterprise AI Integration](https://arxiv.org/abs/2504.19997)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org/abs/2504.17934)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[DoomArena: A framework for Testing AI Agents Against Evolving Security Threats](https://arxiv.org/abs/2504.14064)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](https://arxiv.org/abs/2504.13192)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System](https://arxiv.org/abs/2504.12757)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Progent: Programmable Privilege Control for LLM Agents](https://arxiv.org/abs/2504.11703)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](https://arxiv.org/abs/2504.11281)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[RealHarm: A Collection of Real-World Language Model Application Failures](https://arxiv.org/abs/2504.10277)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies](https://arxiv.org/abs/2504.08623)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Detecting Malicious AI Agents Through Simulated Interactions](https://arxiv.org/abs/2504.03726)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits](https://arxiv.org/abs/2504.03767)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions](https://arxiv.org/abs/2503.23278)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/03] **[Get the Agents Drunk: Memory Perturbations in Autonomous Agent-based Recommender Systems](https://arxiv.org/abs/2503.23804)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/03] **[ShieldAgent: Shielding Agents via Verifiable Safety Policy Reasoning](https://arxiv.org/abs/2503.22738)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/03] **[sudo rm -rf agentic_security](https://arxiv.org/abs/2503.20279)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/03] **[Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents](https://arxiv.org/abs/2503.15547)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/02] **[DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent](https://arxiv.org/abs/2502.12575)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
- [2025/02] **["Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents](https://arxiv.org/abs/2502.11355)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Agent](https://img.shields.io/badge/Agent-87b800)
