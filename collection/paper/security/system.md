# B4. System
- [2025/05] **[BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models](https://arxiv.org/abs/2505.16670)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study](https://arxiv.org/abs/2505.02502)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Hoist with His Own Petard: Inducing Guardrails to Facilitate Denial-of-Service Attacks on Retrieval-Augmented Generation of LLMs](https://arxiv.org/abs/2504.21680)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Are You Getting What You Pay For? Auditing Model Substitution in LLM APIs](https://arxiv.org/abs/2504.04715)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Auditing Prompt Caching in Language Model APIs](https://arxiv.org/abs/2502.07776)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[An Engorgio Prompt Makes Large Language Model Babble on](https://arxiv.org/abs/2412.19394)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Crabs: Consuming Resrouce via Auto-generation for LLM-DoS Attack under Black-box Settings](https://arxiv.org/abs/2412.13879)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks](https://arxiv.org/abs/2411.13757)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Towards evaluations-based safety cases for AI scheming](https://arxiv.org/abs/2411.03336)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Safeguard is a Double-edged Sword: Denial-of-service Attack on Large Language Models](https://arxiv.org/abs/2410.02916)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Exploiting LLM Quantization](https://arxiv.org/abs/2405.18137)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Attacks on Third-Party APIs of Large Language Models](https://arxiv.org/abs/2404.16891)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Towards AI Safety: A Taxonomy for AI System Evaluation](https://arxiv.org/html/2404.05388v1)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[SecGPT: An Execution Isolation Architecture for LLM-Based Systems](https://arxiv.org/abs/2403.04960)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications](https://arxiv.org/abs/2403.02817)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems](https://arxiv.org/abs/2402.18649)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A First Look at GPT Apps: Landscape and Vulnerability](https://arxiv.org/abs/2402.15105)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Apps](https://img.shields.io/badge/Apps-87b800)
