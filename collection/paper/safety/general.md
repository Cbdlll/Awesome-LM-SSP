# A0. General
- [2024/05] **[S-Eval: Automatic and Adaptive Test Generation for Benchmarking Safety Evaluation of Large Language Models](https://arxiv.org/abs/2405.14191)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Introducing v0.5 of the AI Safety Benchmark from MLCommons](https://arxiv.org/abs/2404.12241)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[ALERT: A Comprehensive Benchmark for Assessing Large Language Models' Safety through Red Teaming](https://arxiv.org/abs/2404.08676)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity, Bias and Propensity for Hallucinations](https://arxiv.org/abs/2404.09785)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Foundational Challenges in Assuring Alignment and Safety of Large Language Models](https://llm-safety-challenges.github.io/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/04] **[Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward](https://arxiv.org/abs/2404.08517)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety](https://arxiv.org/abs/2404.05399)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
